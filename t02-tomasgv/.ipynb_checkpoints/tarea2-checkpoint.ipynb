{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUS9F2R-y6lW"
   },
   "source": [
    "# T02\n",
    "\n",
    "Tomás González Villarroel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2qvh2Z1G7EXy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULdqUa1xy8X7"
   },
   "source": [
    "## Definición de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aYY-ffFD0TBB"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self, data, target, depth=0, division=None, value=None):\n",
    "        self.division = division \n",
    "        self.value = value \n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.children = None\n",
    "        self.answer = None\n",
    "        self.depth = depth\n",
    "        self.es_hoja = False\n",
    "        self.es_categorico = True\n",
    "        self.bin = None\n",
    "        self.predict_data = None\n",
    "\n",
    "\n",
    "    def calculate_entropy(self):\n",
    "        \"\"\"\n",
    "        Calcula la entropía del nodo y la retorna\n",
    "        \"\"\"\n",
    "        grouped = self.data[self.target].value_counts()\n",
    "        self.answer = grouped.idxmax()\n",
    "\n",
    "        total = len(self.data)\n",
    "        entropy = -1 * np.sum([g/total * np.log2(g/total) for g in grouped])\n",
    "        return entropy\n",
    "\n",
    "    def get_best_division(self, strategy='median', cut_type='traditional'):\n",
    "        \"\"\"\n",
    "        Retorna el nombre de la/s columna/s con las cuales hará la división el nodo.\n",
    "        \"\"\"\n",
    "        gains = {}\n",
    "        tipos = {}\n",
    "        bins = {}\n",
    "        entropy = self.calculate_entropy()\n",
    "        if entropy == 0:\n",
    "            self.es_hoja = True\n",
    "            return False\n",
    "        total_cols = self.data.drop(self.target, axis=1).columns\n",
    "        total_data = len(self.data)\n",
    "\n",
    "        if not total_data:\n",
    "            self.es_hoja = True\n",
    "            return None\n",
    "        nodo_posible = Node(None, self.target, depth=self.depth + 1)\n",
    "        \n",
    "        if cut_type == 'traditional':\n",
    "            for colname in total_cols:\n",
    "                col = self.data[colname]\n",
    "                tipos[colname] = True\n",
    "                if col.dtype.name != 'object':\n",
    "                    col, bin = self.bining(col, strategy)\n",
    "                    tipos[colname] = False\n",
    "                    bins[colname] = bin\n",
    "                values = col.value_counts().to_dict()\n",
    "                gains[colname] = entropy\n",
    "                split_info = 0\n",
    "                for v in values:\n",
    "                    new_data = self.data[col == v]\n",
    "                    if len(new_data) == 0:\n",
    "                        continue\n",
    "                    if col.dtype.name == 'object':\n",
    "                        new_data = new_data.drop(col.name, axis=1)\n",
    "                    nodo_posible.data = new_data\n",
    "                    nodo_posible.value = v\n",
    "                    gains[colname] -= len(new_data)/total_data * nodo_posible.calculate_entropy()\n",
    "                    split_info -= values[v]/total_data * np.log2(values[v]/total_data)\n",
    "                if split_info != 0:\n",
    "                    gains[colname] /= split_info\n",
    "\n",
    "            result = max(gains, key=gains.get)\n",
    "            self.division = result\n",
    "            self.es_categorico = tipos[result]\n",
    "            if not self.es_categorico:\n",
    "                self.bin = bins[result]\n",
    "            return result\n",
    "        else:\n",
    "            if len(total_cols) < 2:\n",
    "                self.es_hoja = True\n",
    "                return None\n",
    "            \n",
    "            values = []\n",
    "            for col in total_cols:\n",
    "                col = self.data[col]\n",
    "                tipos[col.name] = True\n",
    "                if col.dtype.name != 'object':\n",
    "                    col, bin = self.bining(col, strategy)\n",
    "                    tipos[col.name] = False\n",
    "                    bins[col.name] = bin\n",
    "                values.append(col.value_counts().to_dict())\n",
    "\n",
    "            for i in range(len(total_cols)):\n",
    "                for j in range(i + 1, len(total_cols)):\n",
    "                    col1, col2 = self.data[total_cols[i]], self.data[total_cols[j]]\n",
    "                    gains[(col1.name, col2.name)] = entropy\n",
    "                    split_info = 0\n",
    "                    for v1 in values[i]:\n",
    "                        for v2 in values[j]:\n",
    "                            new_data = self.data[(col1 == v1) & (col2 == v2)]\n",
    "                            if len(new_data) == 0:\n",
    "                                gains[(col1.name, col2.name)] = 0\n",
    "                                continue\n",
    "                            if col1.dtype.name == 'object':\n",
    "                                new_data = new_data.drop(col1.name, axis=1)\n",
    "                            if col2.dtype.name == 'object':\n",
    "                                new_data = new_data.drop(col2.name, axis=1)\n",
    "                            nodo_posible.data = new_data\n",
    "                            nodo_posible.value = (v1, v2)\n",
    "                            gains[(col1.name, col2.name)] -= len(new_data)/total_data * nodo_posible.calculate_entropy()\n",
    "                            split_info -= len(new_data)/total_data * np.log2(len(new_data)/total_data)\n",
    "                    if split_info != 0:\n",
    "                        gains[(col1.name, col2.name)] /= split_info\n",
    "                    \n",
    "\n",
    "            result = max(gains, key=gains.get)\n",
    "            self.division = result\n",
    "            self.es_categorico = (tipos[result[0]], tipos[result[1]])\n",
    "            self.bin = [False, False]\n",
    "            if not self.es_categorico[0]:\n",
    "                self.bin[0] = bins[result[0]]\n",
    "            if not self.es_categorico[1]:\n",
    "                self.bin[1] = bins[result[1]]\n",
    "            return result\n",
    "\n",
    "    def bining(self, column, strategy='median', use_bin=False):\n",
    "        \"\"\"\n",
    "        Recibe una columa que tiene datos numéricos  y retorna un DataFrame.\n",
    "        Por defecto usa la mediana, pero puede especificarse usar la media\n",
    "        \"\"\"\n",
    "        if use_bin:\n",
    "            value = self.bin\n",
    "            if type(value) == list:\n",
    "                for i in range(2):\n",
    "                    if self.division[i] == column.name:\n",
    "                        value = value[i]\n",
    "        else:\n",
    "            if strategy == 'median':\n",
    "                value = column.median()\n",
    "            elif strategy == 'mean':\n",
    "                value = column.mean()\n",
    "            else:\n",
    "                raise ValueError('Estrategia no soportada')\n",
    "        column = column.apply(lambda x: 1 if x > value else 0)\n",
    "        return column, value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fbaIIGGXyx3E"
   },
   "outputs": [],
   "source": [
    "# Código clase árbol\n",
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, cut_type, strategy, max_depth=None, min_data=None, ignore_cols=None):\n",
    "        self.cut_type = cut_type\n",
    "        self.strategy = strategy\n",
    "        self.max_depth = max_depth\n",
    "        self.min_data = min_data\n",
    "        self.root = None\n",
    "        self.ignore_cols = ignore_cols\n",
    "\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        for col in self.ignore_cols:\n",
    "            X = X.drop(col, axis=1)\n",
    "        X[Y.name] = Y\n",
    "        self.root = Node(X, Y.name)\n",
    "        por_chequear = [self.root]\n",
    "\n",
    "        if self.cut_type == 'traditional':\n",
    "            while por_chequear:\n",
    "                node = por_chequear.pop(0)\n",
    "                division = node.get_best_division(self.strategy)\n",
    "                if not self.check_deep(node) or not self.check_min_data(node):\n",
    "                    node.es_hoja = True\n",
    "                    continue\n",
    "                if division:\n",
    "                    col = node.data[division]\n",
    "                    if col.dtype.name != 'object':\n",
    "                        col, bin = node.bining(col, self.strategy)\n",
    "                    values = col.value_counts().to_dict()\n",
    "                    child_nodes = []\n",
    "                    for v in values:\n",
    "                        new_data = node.data[col == v]\n",
    "                        if col.dtype.name == 'object':\n",
    "                            new_data = new_data.drop(col.name, axis=1)\n",
    "                        child = Node(new_data, node.target, depth=node.depth + 1, value=v)\n",
    "                        child_nodes.append(child)\n",
    "                        por_chequear.append(child)\n",
    "                    node.children = child_nodes\n",
    "\n",
    "        else:\n",
    "            while por_chequear:\n",
    "                node = por_chequear.pop(0)\n",
    "                divisiones = node.get_best_division(self.strategy, 'transversal')\n",
    "                if not self.check_deep(node) or not self.check_min_data(node):\n",
    "                    node.es_hoja = True\n",
    "                    continue\n",
    "                if divisiones:\n",
    "                    values = []\n",
    "                    cols = []\n",
    "                    for col in divisiones:\n",
    "                        col = node.data[col]\n",
    "                        if col.dtype.name != 'object':\n",
    "                            col, bin = node.bining(col, self.strategy)\n",
    "                        cols.append(col)\n",
    "                        values.append(col.value_counts().to_dict())\n",
    "\n",
    "                    child_nodes = []\n",
    "                    for v1 in values[0]:\n",
    "                        for v2 in values[1]:\n",
    "                            new_data = node.data[(cols[0] == v1) & (cols[1] == v2)]\n",
    "                            if len(new_data) == 0:\n",
    "                                continue\n",
    "                            if cols[0].dtype.name == 'object':\n",
    "                                new_data = new_data.drop(cols[0].name, axis=1)\n",
    "                            if cols[1].dtype.name == 'object':\n",
    "                                new_data = new_data.drop(cols[1].name, axis=1)\n",
    "                            child = Node(new_data, node.target, depth=node.depth + 1, value=(v1, v2))\n",
    "                            child_nodes.append(child)\n",
    "                            por_chequear.append(child)\n",
    "                    node.children = child_nodes\n",
    "\n",
    "        return self.root\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predice la columna resultante a partir de los datos X\n",
    "        \"\"\"\n",
    "        por_chequear = [self.root]\n",
    "        predicted = {}\n",
    "        self.root.predict_data = X\n",
    "        if self.cut_type == 'traditional':\n",
    "            while por_chequear:\n",
    "                node = por_chequear.pop(0)\n",
    "                if node.es_hoja:\n",
    "                    for i in list(node.predict_data.index.values):\n",
    "                        predicted[i] = node.answer\n",
    "                else:\n",
    "                    col = node.predict_data[node.division]\n",
    "                    if col.dtype.name != 'object':\n",
    "                        col, bin = node.bining(col, self.strategy, True)\n",
    "\n",
    "                    for child in node.children:\n",
    "                        child.predict_data = node.predict_data[col == child.value]\n",
    "                        por_chequear.append(child)\n",
    "        else:\n",
    "            while por_chequear:\n",
    "                node = por_chequear.pop(0)\n",
    "                if node.es_hoja:\n",
    "                    for i in list(node.predict_data.index.values):\n",
    "                        predicted[i] = node.answer\n",
    "                else:\n",
    "                    col1 = node.predict_data[node.division[0]]\n",
    "                    col2 = node.predict_data[node.division[1]]\n",
    "                    if col1.dtype.name != 'object':\n",
    "                        col1, bin = node.bining(col1, self.strategy, True)\n",
    "                    if col2.dtype.name != 'object':\n",
    "                        col2, bin = node.bining(col2, self.strategy, True)\n",
    "\n",
    "                    for child in node.children:\n",
    "                        child.predict_data = node.predict_data[(col1 == child.value[0]) & (col2 == child.value[1])]\n",
    "                        por_chequear.append(child)\n",
    "        return pd.Series(predicted).sort_index()\n",
    "\n",
    "\n",
    "    def check_deep(self, node):\n",
    "        \"\"\"\n",
    "        Retorna True o False dependiendo si el nodo puede seguir \n",
    "        su propagación en función de max_depth\n",
    "        \"\"\"\n",
    "        if not self.max_depth:\n",
    "            return True\n",
    "        return node.depth < self.max_depth\n",
    "\n",
    "\n",
    "    def check_min_data(self, node):\n",
    "        \"\"\"\n",
    "        Retorna True o False dependiendo si el nodo puede seguir \n",
    "        su propagación en función de la cantidad mínima de datos\n",
    "        \"\"\"\n",
    "        if not self.min_data:\n",
    "            return True\n",
    "        return len(node.data) >= self.min_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2q-yAVjd1jja"
   },
   "source": [
    "## Comparar resultados\n",
    "\n",
    "Antes de comparar los resultados, se cargan los datos y se define la función para obtener el rendimiento del árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kGzXrAqh3DJF"
   },
   "outputs": [],
   "source": [
    "# En esta sección se encargan de abrir el dataset y dejarlo en formato X, Y para train y test.\n",
    "df_train = pd.read_csv('datasets/train_small.csv')\n",
    "X_train = df_train\n",
    "Y_train = df_train['state']\n",
    "\n",
    "df_test = pd.read_csv('datasets/test_small.csv')\n",
    "X_test = df_test\n",
    "Y_test= df_test['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "g4CZrzFw5BYk"
   },
   "outputs": [],
   "source": [
    "def performance(y_real, y_predicted):\n",
    "    total_data = len(y_predicted)\n",
    "    correct = 0\n",
    "    # Solo se tomará en cuenta las filas que sí están en el set de testeo\n",
    "    for i in list(y_predicted.index.values):\n",
    "        if y_real[i] == y_predicted[i]:\n",
    "            correct += 1\n",
    "    return correct/total_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSn2NRF928QD"
   },
   "source": [
    "### Estrategia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUHOHsc7_PTc"
   },
   "source": [
    "Debido al gran tiempo que demora el árbol en generarse, se le entregó el hiper-parámetro `max_depth=3` en ambos árboles, de modo que solo se diferencien en el tipo de estrategia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-x1lyQiJqp7G"
   },
   "outputs": [],
   "source": [
    "# En esta sección se encargan de entrenar 2 árboles según distinto tipo de corte y luego comparar los resultados\n",
    "# con el set de test\n",
    "tree_median = DecisionTree('traditional', 'median', max_depth=3, ignore_cols=['name', 'ID', 'state'])\n",
    "tree_mean = DecisionTree('traditional', 'mean', max_depth=3, ignore_cols=['name', 'ID', 'state'])\n",
    "\n",
    "tree_median.fit(X_train, Y_train)\n",
    "tree_mean.fit(X_train, Y_train)\n",
    "\n",
    "Y_median = tree_median.predict(X_test)\n",
    "Y_mean = tree_mean.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "DkfXwCRJqrMg",
    "outputId": "b8b7e1f5-c166-4b54-a4bb-fc1275aa5b1e"
   },
   "outputs": [],
   "source": [
    "print('Usando mediana se obtuvo un desempeño de', performance(Y_test, Y_median))\n",
    "print('Usando media se obtuvo un desempeño de', performance(Y_test, Y_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etNQUEWaN7sZ"
   },
   "source": [
    "A partir de los resultados, obtenemos que el mejor desemeño fue con la estrategia de media, superando por aproximadamente 0.3% a la estrategia de mediana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cr4GmKnY3Ls7"
   },
   "source": [
    "### Tipo de corte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QlLmaUht1nAt"
   },
   "outputs": [],
   "source": [
    "# En esta sección se encargan de entrenar 2 árboles según estrategia y luego comparar los resultados\n",
    "# con el set de test\n",
    "tree_traditional = DecisionTree('traditional', 'mean', max_depth=3, ignore_cols=['name', 'ID', 'state'])\n",
    "tree_transversal = DecisionTree('transversal', 'mean', max_depth=3, ignore_cols=['name', 'ID', 'state'])\n",
    "\n",
    "tree_traditional.fit(X_train, Y_train)\n",
    "tree_transversal.fit(X_train, Y_train)\n",
    "\n",
    "Y_traditional = tree_traditional.predict(X_test)\n",
    "Y_transversal = tree_transversal.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "uHa-j7n87La3",
    "outputId": "abd67b98-f95d-4de6-85d5-9a9e33355b37"
   },
   "outputs": [],
   "source": [
    "print('Usando corte tradicional se obtuvo un desempeño de', performance(Y_test, Y_traditional))\n",
    "print('Usando corte transversal se obtuvo un desempeño de', performance(Y_test, Y_transversal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oxj3q-xiq-JR"
   },
   "source": [
    "A partir de los resultados, obtenemos que el mejor desemeño fue con el tipo de corte tradicional, superando por aproximadamente 1% al corte transversal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YF0Bz4Dg3MEK"
   },
   "source": [
    "### Hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdW0iXTpEqgO"
   },
   "source": [
    "#### Árbol con ambos hiper-parámetros como `None`\n",
    "Para esta parte tuve enormes dificultades dado el tiempo que demora el árbol en generarse, por lo que tuve que usar al menos un hiper-parámetro para poder seguir avanzando con la tarea ☹️ .\n",
    "\n",
    "Se tomará como árbol base el que posee máximo de profundidad de tres niveles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Ac-TOOMy3Ls9",
    "outputId": "ab4cc365-4d0e-45b4-9df6-6164dab8e962"
   },
   "outputs": [],
   "source": [
    "# En esta sección se encargan de entrenar 4 árboles distintos y luego comparar los resultados\n",
    "# con el set de test\n",
    "tree = DecisionTree('traditional', 'mean', max_depth=3, ignore_cols=['name', 'ID', 'state'])\n",
    "tree.fit(X_train, Y_train)\n",
    "Y_predicted = tree.predict(X_test)\n",
    "performance(Y_test, Y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EXrI5TpFNWN"
   },
   "source": [
    "### Árbol cambiando el hiper-parámetro `min_data`\n",
    "Ahora se procede a cambiar el hiper-parámetro de mínimo de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "BVl8qnT-rRMI",
    "outputId": "d16473db-104c-40b4-acb7-ae59b54e87f3"
   },
   "outputs": [],
   "source": [
    "for i in [50, 100, 500, 1000]:\n",
    "    tree = DecisionTree('traditional', 'mean', max_depth=3, min_data = i, ignore_cols=['name', 'ID', 'state'])\n",
    "    tree.fit(X_train, Y_train)\n",
    "    Y_predicted = tree.predict(X_test)\n",
    "    print(f'Rendimiento con un mínimo de {i} datos:', performance(Y_test, Y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZWqOzbHvzl8"
   },
   "source": [
    "Se observa que al aumentar el mínimo de datos, el rendimiento aumenta ligeramente, y se mantiene estable desde 500 datos como mínimo.\n",
    "\n",
    "Por lo tanto, el mejor valor para especificar como mínimo de datos es entre 500 y 1000. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1aQBQ-HXHU9D"
   },
   "source": [
    "### Árbol cambiando el hiper-parámetro `max_depth`\n",
    "\n",
    "Ahora se procede a cambiar el hiper-parámetro de máximo nivel de profundidad:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "CW7aRmZNrRYO",
    "outputId": "393d925c-633a-4ec3-d4be-a89a2676c60c"
   },
   "outputs": [],
   "source": [
    "for i in [2, 3, 4]:\n",
    "    tree = DecisionTree('traditional', 'mean', max_depth = i, ignore_cols=['name', 'ID', 'state'])\n",
    "    tree.fit(X_train, Y_train)\n",
    "    Y_predicted = tree.predict(X_test)\n",
    "    print(f'Rendimiento con un máximo de {i} niveles de profundidad:', performance(Y_test, Y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGbE2SNXxKyX"
   },
   "source": [
    "Se observa que con dos niveles de profundidad el rendimiento disminuye bastante (cerca de 10%), luego aumenta con tres niveles, y finalmente vuelve a disminuir con cuatro niveles.\n",
    "\n",
    "Por lo tanto, el mejor valor para considerar como máximo de profundidad es 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RrilQpXGy0v"
   },
   "source": [
    "### Árbol cambiando ambos hiper-parámetros\n",
    "\n",
    "Finalmente, se preocede a cambiar ambos hiper-parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "rLHp9HGzrRjC",
    "outputId": "0232aa91-518c-4f6b-a948-b48e78656f43"
   },
   "outputs": [],
   "source": [
    "print('Rendimiento con:')\n",
    "for i, j in [(3, 50), (3, 500), (3, 1000), (4, 500), (2, 500)]:\n",
    "    tree = DecisionTree('traditional', 'mean', max_depth = i, min_data = j, ignore_cols=['name', 'ID', 'state'])\n",
    "    tree.fit(X_train, Y_train)\n",
    "    Y_predicted = tree.predict(X_test)\n",
    "    performance(Y_test, Y_predicted)\n",
    "    print(f'Máximo de {i} niveles de profundidad y mínimo de {j} datos:', performance(Y_test, Y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PT9OFkL_y1Um"
   },
   "source": [
    "Se observa que la combinación de hiper-parámetros con mejor rendimiento fue especificar 3 niveles de profundidad y entre 500 y 1000 datos mínimos, donde el rendimiento se mantuvo igual.\n",
    "\n",
    "Finalmente, el desempeño del árbol cambió en mayor proporción al variar la profundidad máxima, teniendo tanto su peor desempeño (2 niveles) como su mejor desempeño (3 niveles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDm4p2B33itl"
   },
   "source": [
    "## Visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvNT92Akdcvu"
   },
   "source": [
    "Para visualizar el árbol, se hará uso de la librería `graphviz`, y en particular se usará la clase `Digraph`.\n",
    "\n",
    "En cada nodo se especifica su división, número de muestras en el nodo y predicción. Si es un nodo hoja, en lugar de división se menciona que es hoja.\n",
    "\n",
    "En cada arista de un nodo a su hijo, se especifica el valor que toma entre paréntesis. Si es un atributo contínuo, se especifica si es mayor (>), o menor o igual (<=) al valor usado para separarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "YJZ7AhU-CErt",
    "outputId": "15454f6d-2f60-4f4d-c04a-3e7312ed6c80"
   },
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "BhrLEPA05VMO",
    "outputId": "f2592ceb-23a0-402f-d269-97792a45536c"
   },
   "outputs": [],
   "source": [
    "tree = DecisionTree('traditional', 'mean', max_depth=3, ignore_cols=['name', 'ID', 'state'])\n",
    "tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEF_DP12Mqtv"
   },
   "outputs": [],
   "source": [
    "def create_graph(tree):\n",
    "    \"\"\"\n",
    "    Crea la visaulización del árbol con corte tradicional\n",
    "    \"\"\"\n",
    "    g = graphviz.Digraph('G', filename='graph.gv')\n",
    "    g.attr('node', shape='square')\n",
    "    por_recorrer = [tree]\n",
    "    nodes = {}\n",
    "    index = 0\n",
    "    nodes[tree] = index\n",
    "    g.node(f'struct{index}', f'División: {tree.division}\\nSamples: {len(tree.data)}\\nPredicción: {tree.answer}')\n",
    "    while por_recorrer:\n",
    "        node = por_recorrer.pop(0)\n",
    "        if node.es_hoja:\n",
    "            continue\n",
    "        for child in node.children:   \n",
    "            index += 1  \n",
    "            nodes[child] = index\n",
    "            if not node.es_categorico:\n",
    "                if child.value:\n",
    "                    added = '> '\n",
    "                else:\n",
    "                    added = '<= '\n",
    "                added += str(node.bin)\n",
    "            else:\n",
    "                added = child.value\n",
    "            if not child.es_hoja:\n",
    "                g.node(f'struct{index}', f'División: {child.division}\\nSamples: {len(child.data)}\\nPredicción: {child.answer}')\n",
    "            else:\n",
    "                g.node(f'struct{index}', f'División: Es hoja\\nSamples: {len(child.data)}\\nPredicción: {child.answer}')\n",
    "            g.edge(f'struct{nodes[node]}', f'struct{index}', label=f'({added})')\n",
    "\n",
    "        por_recorrer.extend(node.children)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "isJ6SP8IKQky",
    "outputId": "0c8a4f51-875f-4fc7-e457-22970c68dbfa"
   },
   "outputs": [],
   "source": [
    "create_graph(tree.root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2QYj90Z4RX5"
   },
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "HC0ZLxe8OtMi",
    "outputId": "ec96f7eb-326f-4662-f0e1-7b505790efc6"
   },
   "outputs": [],
   "source": [
    "tree = DecisionTree('transversal', 'mean', max_depth=3, ignore_cols=['name', 'ID', 'state'])\n",
    "tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Qy7N_yW4Q2m"
   },
   "outputs": [],
   "source": [
    "def create_graph_transversal(tree):\n",
    "    \"\"\"\n",
    "    Crea la visaulización del árbol con corte transversal\n",
    "    \"\"\"\n",
    "    g = graphviz.Digraph('G', filename='graph.gv')\n",
    "    g.attr('node', shape='square')\n",
    "    por_recorrer = [tree]\n",
    "    nodes = {}\n",
    "    index = 0\n",
    "    nodes[tree] = index\n",
    "    tree_label = ' & '.join(tree.division)\n",
    "    g.node(f'struct{index}', f'División: {tree_label}\\nSamples: {len(tree.data)}\\nPredicción: {tree.answer}')\n",
    "    while por_recorrer:\n",
    "        node = por_recorrer.pop(0)\n",
    "        if node.es_hoja:\n",
    "            continue\n",
    "        for child in node.children:   \n",
    "            index += 1  \n",
    "            nodes[child] = index\n",
    "            if not node.es_categorico[0]:\n",
    "                if child.value[0]:\n",
    "                    added_1 = '> '\n",
    "                else:\n",
    "                    added_1 = '<= '\n",
    "                added_1 += str(round(node.bin[0], 2))\n",
    "            else:\n",
    "                added_1 = child.value[0]\n",
    "            if not node.es_categorico[1]:\n",
    "                if child.value[1]:\n",
    "                    added_2 = '> '\n",
    "                else:\n",
    "                    added_2 = '<= '\n",
    "                added_2 += str(round(node.bin[1], 2))\n",
    "            else:\n",
    "                added_2 = child.value[1]\n",
    "            label = f'{added_1} & {added_2}'\n",
    "            added_1 + \"&\" + added_2 + f'{child.value[1]}'\n",
    "            if not child.es_hoja:\n",
    "                div_label = ' & '.join(child.division)\n",
    "                g.node(f'struct{index}', f'División: {div_label}\\nSamples: {len(child.data)}\\nPredicción: {child.answer}')\n",
    "            else:\n",
    "                g.node(f'struct{index}', f'División: Es hoja\\nSamples: {len(child.data)}\\nPredicción: {child.answer}')\n",
    "            g.edge(f'struct{nodes[node]}', f'struct{index}', label=f'({label})')\n",
    "\n",
    "        por_recorrer.extend(node.children)\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zsx7vEXWbxTx",
    "outputId": "b2f2dcf1-4fa4-46b1-b5a6-d679f0fd6563"
   },
   "outputs": [],
   "source": [
    "create_graph_transversal(tree.root)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copia de tarea2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
