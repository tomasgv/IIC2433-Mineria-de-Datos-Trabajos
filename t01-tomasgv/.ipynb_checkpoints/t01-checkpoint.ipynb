{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pP75rcgQJcJG"
   },
   "source": [
    "# Tarea 1: Reglas de Asociación\n",
    "\n",
    "Autor: Tomás González Villarroel\n",
    "\n",
    "Comenzaremos importando las librerías a usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FMLHqHUJcJH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xsPatydtJcJL"
   },
   "source": [
    "## Parte 1: Preprocesamiento de datos\n",
    "\n",
    "A continuación, se implementarán las funciones para el manejo del _dataset_.\n",
    "\n",
    "\n",
    "### 1.1 `preprocess(df)`\n",
    "\n",
    "Con esta función se dejan solo las columnas pertinentes, se quitan los valores nulos y se dejan solo aquellas filas que tengan rating mayor o igual a 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmtOADnkJcJM"
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    '''\n",
    "    Función que preprocesa los DataFrames. \n",
    "    En primer lugar solo queda con las columnas userId, movieId y rating.\n",
    "    Luego quita aquellas filas con algún valor nulo.\n",
    "    Finalmente deja en el DataFrame solo las filas con rating mayor o igual a 4\n",
    "    '''\n",
    "    df = df[['userId', 'movieId', 'rating']]\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    df = df[df.rating >= 4.0]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se prueba la función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357892</th>\n",
       "      <td>11482</td>\n",
       "      <td>2571</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357893</th>\n",
       "      <td>11482</td>\n",
       "      <td>2959</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357896</th>\n",
       "      <td>11482</td>\n",
       "      <td>3552</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357897</th>\n",
       "      <td>11482</td>\n",
       "      <td>3578</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357899</th>\n",
       "      <td>11482</td>\n",
       "      <td>4223</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>676518 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  movieId  rating\n",
       "6             1      151     4.0\n",
       "7             1      223     4.0\n",
       "8             1      253     4.0\n",
       "9             1      260     4.0\n",
       "10            1      293     4.0\n",
       "...         ...      ...     ...\n",
       "1357892   11482     2571     4.0\n",
       "1357893   11482     2959     4.0\n",
       "1357896   11482     3552     4.0\n",
       "1357897   11482     3578     4.0\n",
       "1357899   11482     4223     4.0\n",
       "\n",
       "[676518 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('ratings.csv')\n",
    "preprocessed = preprocess(ratings)\n",
    "preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-BEE5-OdJcJR"
   },
   "source": [
    "## 1.2 `dataframe_to_ndarray(df)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBJcwiNhJcJS"
   },
   "outputs": [],
   "source": [
    "def dataframe_to_ndarray(df):\n",
    "    '''\n",
    "    Función que transforma DataFrame a ndarray.\n",
    "    Primero se agrupan los datos según 'userId'.\n",
    "    Luego se aplica list de modo que se tenga en la columna 'movieId'\n",
    "    todas las películas que al respectivo usuario le han gustado.\n",
    "    Finalmente se aplica np.to_array para transformar cada lista\n",
    "    y la columna en array.\n",
    "    '''\n",
    "    # Inspirado en https://stackoverflow.com/questions/34143988/pandas-group-by-to-convert-different-rows-to-one-row-with-array-of-values\n",
    "    result = preprocessed.groupby(by=['userId'])['movieId'].apply(list).apply(lambda x: np.array(x))\n",
    "    \n",
    "    # Retornamos un n-dimensional array\n",
    "    return result.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0JEBBex3JcJW"
   },
   "source": [
    "Se prueba la función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HB2VfYp8JcJW",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([  151,   223,   253,   260,   293,   296,   318,   541,  1036,\n",
       "        1079,  1090,  1097,  1196,  1198,  1200,  1214,  1215,  1219,\n",
       "        1240,  1249,  1258,  1259,  1266,  1278,  1321,  1333,  1358,\n",
       "        1374,  1387,  1967,  2021,  2100,  2118,  2138,  2140,  2143,\n",
       "        2173,  2174,  2193,  2288,  2291,  2542,  2628,  2762,  2872,\n",
       "        2944,  2959,  2968,  3081,  3153,  3479,  3489,  3499,  3889,\n",
       "        3996,  4011,  4027,  4128,  4306,  4467,  4571,  4754,  4896,\n",
       "        4911,  4993,  5026,  5039,  5171,  5540,  5797,  5816,  5952,\n",
       "        6093,  6333,  6539,  6754,  6774,  7046,  7153,  7389,  7438,\n",
       "        7454,  7757,  8368,  8507,  8636,  8961, 31696]),\n",
       "       array([   3,   62,   70,  110,  260,  266,  480,  541,  589,  908,  924,\n",
       "       1196, 1210, 1214, 1249, 1259, 1270, 1327, 1356, 1544, 1580, 1673,\n",
       "       1748, 1974, 2454, 2455, 2948, 2951, 3150, 3173, 3450, 3513, 3555,\n",
       "       3703, 3753, 3917, 3923, 3926, 3927, 3928, 3930, 3937, 3959]),\n",
       "       array([   1,   32,   50,  175,  223,  260,  316,  318,  329,  457,  480,\n",
       "        490,  541,  589,  593,  610,  788,  858,  904,  919,  924,  953,\n",
       "       1060, 1073, 1077, 1079, 1084, 1089, 1094, 1097, 1103, 1125, 1129,\n",
       "       1193, 1196, 1197, 1198, 1199, 1200, 1206, 1208, 1210, 1213, 1214,\n",
       "       1215, 1219, 1220, 1221, 1222, 1230, 1240, 1242, 1247, 1257, 1258,\n",
       "       1259, 1261, 1266, 1270, 1272, 1276, 1278, 1304, 1307, 1321, 1333,\n",
       "       1345, 1356, 1373, 1374, 1375, 1376, 1544, 1584, 1603, 1653, 1674,\n",
       "       1676, 1721, 1762, 1831, 1876, 1882, 1909, 1917, 1921, 2009, 2018,\n",
       "       2028, 2034, 2046, 2054, 2076, 2093, 2105, 2117, 2118, 2140, 2150,\n",
       "       2236, 2288, 2311, 2329, 2366, 2371, 2391, 2407, 2428, 2448, 2455,\n",
       "       2505, 2528, 2529, 2530, 2532, 2551, 2571, 2613, 2615, 2628, 2640,\n",
       "       2668, 2694, 2710, 2722, 2750, 2788, 2791, 2797, 2808, 2872, 2916,\n",
       "       2918, 2947, 2948, 2949, 2968, 2985, 3033, 3039, 3070, 3072, 3098,\n",
       "       3142, 5060]),\n",
       "       ...,\n",
       "       array([  172,   260,   407,   420,   541,   784,   858,   924,  1080,\n",
       "        1136,  1193,  1196,  1199,  1210,  1220,  1278,  1334,  1653,\n",
       "        1682,  1748,  1884,  1953,  2009,  2021,  2329,  2657,  2788,\n",
       "        2947,  2948,  2949,  2993,  3033,  3384,  3633,  3671,  3868,\n",
       "        3959,  4443,  4678,  6104,  6807,  6957,  7102,  7394,  8874,\n",
       "        8879, 26285, 33493]),\n",
       "       array([  50,  237,  260,  314, 1263, 1617, 2070, 2396, 2858, 3160, 3408,\n",
       "       3481, 3728]),\n",
       "       array([  47,  104, 1208, 1610, 2571, 2959, 3552, 3578, 4223])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndarray_movies = dataframe_to_ndarray(preprocessed)\n",
    "ndarray_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Implementación del algortimo FP-Growth\n",
    "\n",
    "A continuación se implementan las clases `Node` y `FPGrowth`. Se documentó cada método para entregar mayor claridad del funcionamiento.\n",
    "\n",
    "### Consideraciones\n",
    "- El método `mine_tree` retorna una lista de listas.\n",
    "- El método `generate_association_rules` retorna un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PrZfPM-1JcJe"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, id_):\n",
    "        '''\n",
    "        Inicializador de la clase Node.\n",
    "        Contiene los siguientes atributos:\n",
    "        - self.movie_id: Entregado al inicializar, indica el id de la película\n",
    "        - self.children: Diccionario que almacenará los nodos hijos de la forma id_movie: Node\n",
    "        - self.count: Lleva la frecuencia del nodo. Será de utilidad al crear y minar el árbol.\n",
    "        '''\n",
    "        self.movie_id = id_\n",
    "        self.children = {}\n",
    "        self.count = 1\n",
    "\n",
    "class FPGrowth:\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Inicializador de la clase FPGrowth\n",
    "        Contiene los siguientes atributos:\n",
    "        - self.root: Contiene al nodo raíz. Este no tiene id_movie, por lo que se le entrega None.\n",
    "        - self.cpb: Diccionario que almacenará el Conditional Pattern Base. \n",
    "                    Sigue el formato {item: {base: frecuencia, ...}}\n",
    "        - self.fpg: Diccionario que almacenará los Frecuent Pattern Generated. \n",
    "                    Se realizó la creación de Conditional FP-Tree y luego\n",
    "                    se crearon directamente los Frecuent Pattern Generated, \n",
    "                    para almacenar solo estos últimos.\n",
    "                    Sigue el formato: {item: [[itemset_frecuente, frecuencia], ...]}\n",
    "        - self.total_trans: Contendrá la cantidad total de transacciones,\n",
    "                    lo cual será de utilidad para calcular soportes.\n",
    "        - self.perms: Contendrá temporalmente las permutaciones posibles para crear los\n",
    "                    Frecuent Pattern Generated.\n",
    "        '''\n",
    "        self.root = Node(None)\n",
    "        self.cpb = {}\n",
    "        self.fpg = {}\n",
    "        self.total_trans = None\n",
    "        self.perms = []\n",
    "\n",
    "    def create_tree(self, ndarray_movies, min_support):\n",
    "        '''\n",
    "        Método para crear el FP-Tree.\n",
    "        Los pasos seguidos para crear el árbol fueron:\n",
    "        1. Se buscan los itemsets de largo 1 y se calcula su frecuencia\n",
    "        2. Se aplica el umbral min_support y se eliminan los itemsets de soporte menor\n",
    "        3. Se agregan las transacciones según orden de soporte\n",
    "        4. Se crea el árbol usando las transacciones reordenadas\n",
    "        '''\n",
    "        # 1. Método unique sacado de la documentación \n",
    "        # https://numpy.org/doc/stable/reference/generated/numpy.unique.html\n",
    "        itsets_1 = np.unique([item for itemset in ndarray_movies for item in itemset], return_counts=True)\n",
    "        zip_itsets = zip(itsets_1[0], itsets_1[1])\n",
    "\n",
    "        # 2.\n",
    "        self.total_trans = ndarray_movies.shape[0]\n",
    "        itsets_supp = sorted([item for item in zip_itsets if item[1]/self.total_trans >= min_support],\n",
    "                             key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Se preparan los diccionarios a usar cuando se mine el árbol\n",
    "        for item, freq in itsets_supp:\n",
    "            self.cpb[item] = {}\n",
    "            self.fpg[item] = [[[item], freq]]\n",
    "\n",
    "        # 3.\n",
    "        transactions = []\n",
    "        for itemset in ndarray_movies:\n",
    "            trans = []\n",
    "            for item, freq in itsets_supp:\n",
    "                if item in itemset:\n",
    "                    trans.append(item)\n",
    "            if trans:\n",
    "                transactions.append(trans)\n",
    "      \n",
    "        # 4.\n",
    "        for trans in transactions:\n",
    "            self.add_trans(self.root, trans)\n",
    "\n",
    "        #self.print_tree(root)\n",
    "        return self.root\n",
    "\n",
    "\n",
    "    def add_trans(self, root, trans):\n",
    "        '''\n",
    "        Método recursivo para agregar los nodos al árbol siguiendo las transacciones.\n",
    "        '''\n",
    "        # Si ya está en los nodos hijos, se suma uno a su cuenta\n",
    "        if trans[0] in root.children:\n",
    "            root.children[trans[0]].count += 1\n",
    "\n",
    "        # Si no, se crea\n",
    "        else:\n",
    "            root.children[trans[0]] = Node(trans[0])\n",
    "\n",
    "        # Se pasa al siguiente item de la transacción, usando recursión.\n",
    "        if len(trans) > 1:\n",
    "            self.add_trans(root.children[trans[0]], trans[1:])\n",
    "         \n",
    "\n",
    "    def mine_tree(self, fptree, min_support):\n",
    "        '''\n",
    "        Método para minar el FP-Tree.\n",
    "        Los pasos seguidos para minar el árbol fueron:\n",
    "        1. Crear el CPB de cada movie_id\n",
    "        2. Crear el CFP-Tree y FPG de cada movie_id frecuente\n",
    "        3. Generar los itemsets frecuentes\n",
    "        '''\n",
    "\n",
    "        # 1.\n",
    "        for movie_id in self.cpb:\n",
    "            self.get_cpb(fptree, movie_id, [])\n",
    "        #print(self.cpb)\n",
    "\n",
    "        # 2. y 3.\n",
    "        self.get_fpg(min_support)\n",
    "\n",
    "        # Se retorna una lista de listas con los itemsets frecuentes\n",
    "        freq_itemsets = []\n",
    "        for id_movie in self.fpg:\n",
    "            for itemsets in self.fpg[id_movie]:\n",
    "                freq_itemsets.append(itemsets[0])\n",
    "        return freq_itemsets\n",
    "\n",
    "\n",
    "    \n",
    "    def get_cpb(self, node, movie_id, current=[]):\n",
    "        '''\n",
    "        Método recursivo para obtener el CPB.\n",
    "        '''\n",
    "        \n",
    "        # Chequeamos que coincida el nombre y llevemos algo en la lista además del nodo actual\n",
    "        if node.movie_id == movie_id:\n",
    "            if len(current) > 1:\n",
    "                self.cpb[movie_id][tuple(current[:-1])] = node.count\n",
    "\n",
    "        # Si no, agregamos el id a la lista actual y seguimos recorriendo el árbol\n",
    "        else:\n",
    "            for name, child in node.children.items():\n",
    "                self.get_cpb(child, movie_id, current + [name])\n",
    "\n",
    "    def get_fpg(self, min_support):\n",
    "        '''\n",
    "        Método para obtener los FPG.\n",
    "        Sigue los siquientes pasos:\n",
    "        1. Recorre todas las CPB\n",
    "        2. Construye todas las combinaciones para cada item\n",
    "        3. Guarda las combinaciones que tengan soporte \n",
    "           mayor a min_support dentro de self.fpg\n",
    "        '''\n",
    "        # 1.\n",
    "        for item in self.cpb:\n",
    "            \n",
    "            # 2.\n",
    "            every_item = []\n",
    "            for base in self.cpb[item]:\n",
    "                for i in base:\n",
    "                    if i not in every_item:\n",
    "                        every_item.append(i)\n",
    "\n",
    "            if every_item:\n",
    "                # 3.\n",
    "                # Caso 1 item, no se necesitan hacer combinaciones en este.\n",
    "                # Se guarda en comb_items solo aquellos items con soporte mayor o igual a min_support,\n",
    "                # y esta lista se utilizará en el caso de n items\n",
    "                comb_items = []\n",
    "                for current_item in every_item:\n",
    "                    freq_item = 0\n",
    "                    for base in self.cpb[item]:\n",
    "                        if current_item in base:\n",
    "                            freq_item += self.cpb[item][base]\n",
    "                    if freq_item/self.total_trans >= min_support:\n",
    "                        self.fpg[item].append([[current_item, item], freq_item]) \n",
    "                        comb_items.append(current_item)\n",
    "\n",
    "                # Caso n items\n",
    "                # Lógica: Se van creando combinaciones de largo cada vez mayor, \n",
    "                # utilizando los items de comb_items\n",
    "                current_len = 1\n",
    "                while current_len < len(comb_items):\n",
    "                    self.perms = []\n",
    "                    current_len += 1\n",
    "                    self.get_combs(comb_items, current_len)\n",
    "                    \n",
    "                    # Se filtran las bases de largo suficiente como para contener a una de las combinaciones\n",
    "                    long_bases = [b for b in self.cpb[item] if len(b) >= current_len]\n",
    "                    for itset in self.perms:\n",
    "                        freq_item = 0\n",
    "                        for base in long_bases:\n",
    "                            present = True\n",
    "                            \n",
    "                            # Se verifica que cada item de la combinación esté en la base\n",
    "                            for elem in itset:\n",
    "                                if elem not in base:\n",
    "                                    present = False\n",
    "                                    break\n",
    "                            \n",
    "                            # En caso de que esté, se aumenta la frecuencia en el valor correspondiente\n",
    "                            if present:\n",
    "                                freq_item += self.cpb[item][base]\n",
    "                                \n",
    "                        # Finalmente, se agrega a los FPG si el soporte es mayor o igual a min_support\n",
    "                        if freq_item/self.total_trans >= min_support:\n",
    "                            self.fpg[item].append([itset + [item], freq_item])\n",
    "\n",
    "    \n",
    "    def get_combs(self, items, length, result=[]):\n",
    "        '''\n",
    "        Método recursivo auxiliar para definir combinaciones de items.\n",
    "        Utiliza la lista self.perms.\n",
    "        '''\n",
    "        if len(result) == length:\n",
    "            self.perms.append(result)\n",
    "        else:\n",
    "            for i in range(len(items)):\n",
    "                item = items[i]\n",
    "                self.get_combs(items[i + 1:], length, result + [item])\n",
    "\n",
    "\n",
    "    def generate_association_rules(self, freq_itemset, confidence=0, lift=0):\n",
    "        '''\n",
    "        Método para generar reglas de asociación.\n",
    "        Para generar las reglas de asociación se siguieron los siguientes pasos:\n",
    "        1. Eliminar los itemsets frecuentes de largo 1\n",
    "        2. Se generan las reglas de asociación\n",
    "        '''\n",
    "        # 1.\n",
    "        freq_itset = [list(itset) for itset in freq_itemset if len(itset) > 1]\n",
    "        \n",
    "        # Se genera un diccionario con los itemsets frecuentes y sus frecuencias\n",
    "        dic_itsets = {tuple(sorted(subl[0])):subl[1] for v in self.fpg.values() for subl in v}\n",
    "\n",
    "        # 2. (perdón por el spanglish)\n",
    "        antecedentes = []\n",
    "        consecuentes = []\n",
    "        confianzas = []\n",
    "        lifts = []\n",
    "        supports = []\n",
    "        for itset in freq_itset:\n",
    "            for i in range(len(itset)):\n",
    "                for j in range(i):\n",
    "                    ant = itset[j:i]\n",
    "                    cons = itset[0:j] + itset[i:]\n",
    "                    \n",
    "                    # Se obtienen las frecuencias desde el diccionario dic_itsets\n",
    "                    freq_union = dic_itsets[tuple(sorted(ant + cons))]\n",
    "                    freq_cons = dic_itsets[tuple(sorted(cons))]\n",
    "                    freq_ant = dic_itsets[tuple(sorted(ant))]\n",
    "                    conf_ant = freq_union/freq_ant\n",
    "                    conf_cons = freq_union/freq_cons\n",
    "                    lift = (freq_union/self.total_trans) / ((freq_ant/self.total_trans) * (freq_cons/self.total_trans))\n",
    "                    if conf_ant >= confidence:\n",
    "                        antecedentes.append(set(ant))\n",
    "                        consecuentes.append(set(cons))\n",
    "                        confianzas.append(conf_ant)\n",
    "                        lifts.append(lift)\n",
    "                        supports.append(freq_union/self.total_trans)\n",
    "\n",
    "                    if conf_cons >= confidence:\n",
    "                        antecedentes.append(set(cons))\n",
    "                        consecuentes.append(set(ant))\n",
    "                        confianzas.append(conf_cons)\n",
    "                        lifts.append(lift)\n",
    "                        supports.append(freq_union/self.total_trans)\n",
    "\n",
    "        dict_reglas = {'antecedente': antecedentes,\n",
    "                     'consecuente': consecuentes,\n",
    "                     'confianza': confianzas,\n",
    "                     'lift': lifts,\n",
    "                      'support': supports}\n",
    "        \n",
    "        # Entregamos un DataFrame ordenado según valores de lift de mayor a menor\n",
    "        rules = pd.DataFrame(dict_reglas).sort_values(by=['lift'], ascending=False)\n",
    "\n",
    "        return rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QW6iAT09G_Y2"
   },
   "source": [
    "## Parte 3\n",
    "\n",
    "Se selecciona un soporte de 0.15 para tener una cantidad aceptable de reglas de asociación (con soportes mayores disminuyen mucho).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "-mKkezhBb3rX",
    "outputId": "79875075-3a05-4beb-b85c-789f8e95aa47"
   },
   "outputs": [],
   "source": [
    "fp_growth = FPGrowth()\n",
    "\n",
    "tree = fp_growth.create_tree(ndarray_movies, 0.15)\n",
    "\n",
    "mined = fp_growth.mine_tree(tree, 0.15)\n",
    "\n",
    "rules = fp_growth.generate_association_rules(mined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterios de calidad\n",
    "\n",
    "Fundamentado desde comparación de confianza y *lift* en los documentos [[1]](http://faculty.smu.edu/tfomby/eco5385_eco6380/lecture/Association%20Rules_v3.pdf) y [[2]](https://www.solver.com/xlminer/help/association-rules#:~:text=Lift%20is%20one%20more%20parameter,of%20Confidence%20to%20Expected%20Confidence.&text=A%20lift%20ratio%20larger%20than,the%20two%20sets%20were%20independent.).\n",
    "\n",
    "Para la medida absoluta de confianza, le entregaremos un valor de umbral de 0.6, que nos indicará que un 60% de las veces que aparece el antecedente en un *itemset*, también aparecerá el consecuente.\n",
    "\n",
    "Para la medida relativa del *lift*, indicaremos un valor de umbral de 1.2. Podemos decir que el *lift* es la razón entre confianza y confianza esperada, y que los valores de utilidad para las reglas de asociación son mayores a 1, ya que indicarán una dependencia mayor a la esperada con una relación de independencia entre el antecedente y consecuente. A medida que crezca el *lift*, mayor será la dependencia.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "OTrMpSFtGY6b",
    "outputId": "d0465af4-1488-430f-e21a-aca4d3be030e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedente</th>\n",
       "      <th>consecuente</th>\n",
       "      <th>confianza</th>\n",
       "      <th>lift</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{1196}</td>\n",
       "      <td>{1210}</td>\n",
       "      <td>0.689237</td>\n",
       "      <td>2.980724</td>\n",
       "      <td>0.168438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{1210}</td>\n",
       "      <td>{1196}</td>\n",
       "      <td>0.728437</td>\n",
       "      <td>2.980724</td>\n",
       "      <td>0.168438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{260}</td>\n",
       "      <td>{1196}</td>\n",
       "      <td>0.662213</td>\n",
       "      <td>2.709740</td>\n",
       "      <td>0.198572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{1196}</td>\n",
       "      <td>{260}</td>\n",
       "      <td>0.812545</td>\n",
       "      <td>2.709740</td>\n",
       "      <td>0.198572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{260}</td>\n",
       "      <td>{1210}</td>\n",
       "      <td>0.618937</td>\n",
       "      <td>2.676698</td>\n",
       "      <td>0.185595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{1210}</td>\n",
       "      <td>{260}</td>\n",
       "      <td>0.802637</td>\n",
       "      <td>2.676698</td>\n",
       "      <td>0.185595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{1196}</td>\n",
       "      <td>{1198}</td>\n",
       "      <td>0.625089</td>\n",
       "      <td>2.671110</td>\n",
       "      <td>0.152761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{1198}</td>\n",
       "      <td>{1196}</td>\n",
       "      <td>0.652773</td>\n",
       "      <td>2.671110</td>\n",
       "      <td>0.152761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{1198}</td>\n",
       "      <td>{260}</td>\n",
       "      <td>0.668776</td>\n",
       "      <td>2.230288</td>\n",
       "      <td>0.156506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{47}</td>\n",
       "      <td>{296}</td>\n",
       "      <td>0.718677</td>\n",
       "      <td>1.967537</td>\n",
       "      <td>0.160860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  antecedente consecuente  confianza      lift   support\n",
       "0      {1196}      {1210}   0.689237  2.980724  0.168438\n",
       "1      {1210}      {1196}   0.728437  2.980724  0.168438\n",
       "2       {260}      {1196}   0.662213  2.709740  0.198572\n",
       "3      {1196}       {260}   0.812545  2.709740  0.198572\n",
       "4       {260}      {1210}   0.618937  2.676698  0.185595\n",
       "5      {1210}       {260}   0.802637  2.676698  0.185595\n",
       "6      {1196}      {1198}   0.625089  2.671110  0.152761\n",
       "7      {1198}      {1196}   0.652773  2.671110  0.152761\n",
       "8      {1198}       {260}   0.668776  2.230288  0.156506\n",
       "9        {47}       {296}   0.718677  1.967537  0.160860"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rules = fp_growth.generate_association_rules(mined, 0.6, 1.2).reset_index(drop=True).head(10)\n",
    "top_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4\n",
    "\n",
    "A las reglas obtenidas, les entregaremos los nombres y géneros de las películas que tienen asociadas.\n",
    "\n",
    "\n",
    "Primero cargamos los datos de las películas y los dejamos en una estructura de datos cómoda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('movies.csv')\n",
    "\n",
    "# Sacado de https://stackoverflow.com/questions/26716616/convert-a-pandas-dataframe-to-a-dictionary/26716774\n",
    "movies_dict = movies_df.set_index('movieId').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego creamos nuevas columnas con nombres y géneros de películas según los ids presentes en las reglas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedente</th>\n",
       "      <th>consecuente</th>\n",
       "      <th>ant_genero</th>\n",
       "      <th>cons_genero</th>\n",
       "      <th>confianza</th>\n",
       "      <th>lift</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Star Wars: Episode V - The Empire Strikes Back (1980)]</td>\n",
       "      <td>[Star Wars: Episode VI - Return of the Jedi (1983)]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>0.689237</td>\n",
       "      <td>2.980724</td>\n",
       "      <td>0.168438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Star Wars: Episode VI - Return of the Jedi (1983)]</td>\n",
       "      <td>[Star Wars: Episode V - The Empire Strikes Back (1980)]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>0.728437</td>\n",
       "      <td>2.980724</td>\n",
       "      <td>0.168438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Star Wars: Episode IV - A New Hope (1977)]</td>\n",
       "      <td>[Star Wars: Episode V - The Empire Strikes Back (1980)]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>0.662213</td>\n",
       "      <td>2.709740</td>\n",
       "      <td>0.198572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Star Wars: Episode V - The Empire Strikes Back (1980)]</td>\n",
       "      <td>[Star Wars: Episode IV - A New Hope (1977)]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>0.812545</td>\n",
       "      <td>2.709740</td>\n",
       "      <td>0.198572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Star Wars: Episode IV - A New Hope (1977)]</td>\n",
       "      <td>[Star Wars: Episode VI - Return of the Jedi (1983)]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>0.618937</td>\n",
       "      <td>2.676698</td>\n",
       "      <td>0.185595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Star Wars: Episode VI - Return of the Jedi (1983)]</td>\n",
       "      <td>[Star Wars: Episode IV - A New Hope (1977)]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>0.802637</td>\n",
       "      <td>2.676698</td>\n",
       "      <td>0.185595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Star Wars: Episode V - The Empire Strikes Back (1980)]</td>\n",
       "      <td>[Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>[Action|Adventure]</td>\n",
       "      <td>0.625089</td>\n",
       "      <td>2.671110</td>\n",
       "      <td>0.152761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)]</td>\n",
       "      <td>[Star Wars: Episode V - The Empire Strikes Back (1980)]</td>\n",
       "      <td>[Action|Adventure]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>0.652773</td>\n",
       "      <td>2.671110</td>\n",
       "      <td>0.152761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)]</td>\n",
       "      <td>[Star Wars: Episode IV - A New Hope (1977)]</td>\n",
       "      <td>[Action|Adventure]</td>\n",
       "      <td>[Action|Adventure|Sci-Fi]</td>\n",
       "      <td>0.668776</td>\n",
       "      <td>2.230288</td>\n",
       "      <td>0.156506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Seven (a.k.a. Se7en) (1995)]</td>\n",
       "      <td>[Pulp Fiction (1994)]</td>\n",
       "      <td>[Mystery|Thriller]</td>\n",
       "      <td>[Comedy|Crime|Drama|Thriller]</td>\n",
       "      <td>0.718677</td>\n",
       "      <td>1.967537</td>\n",
       "      <td>0.160860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        antecedente  \\\n",
       "0                           [Star Wars: Episode V - The Empire Strikes Back (1980)]   \n",
       "1                               [Star Wars: Episode VI - Return of the Jedi (1983)]   \n",
       "2                                       [Star Wars: Episode IV - A New Hope (1977)]   \n",
       "3                           [Star Wars: Episode V - The Empire Strikes Back (1980)]   \n",
       "4                                       [Star Wars: Episode IV - A New Hope (1977)]   \n",
       "5                               [Star Wars: Episode VI - Return of the Jedi (1983)]   \n",
       "6                           [Star Wars: Episode V - The Empire Strikes Back (1980)]   \n",
       "7  [Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)]   \n",
       "8  [Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)]   \n",
       "9                                                     [Seven (a.k.a. Se7en) (1995)]   \n",
       "\n",
       "                                                                        consecuente  \\\n",
       "0                               [Star Wars: Episode VI - Return of the Jedi (1983)]   \n",
       "1                           [Star Wars: Episode V - The Empire Strikes Back (1980)]   \n",
       "2                           [Star Wars: Episode V - The Empire Strikes Back (1980)]   \n",
       "3                                       [Star Wars: Episode IV - A New Hope (1977)]   \n",
       "4                               [Star Wars: Episode VI - Return of the Jedi (1983)]   \n",
       "5                                       [Star Wars: Episode IV - A New Hope (1977)]   \n",
       "6  [Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)]   \n",
       "7                           [Star Wars: Episode V - The Empire Strikes Back (1980)]   \n",
       "8                                       [Star Wars: Episode IV - A New Hope (1977)]   \n",
       "9                                                             [Pulp Fiction (1994)]   \n",
       "\n",
       "                  ant_genero                    cons_genero  confianza  \\\n",
       "0  [Action|Adventure|Sci-Fi]      [Action|Adventure|Sci-Fi]   0.689237   \n",
       "1  [Action|Adventure|Sci-Fi]      [Action|Adventure|Sci-Fi]   0.728437   \n",
       "2  [Action|Adventure|Sci-Fi]      [Action|Adventure|Sci-Fi]   0.662213   \n",
       "3  [Action|Adventure|Sci-Fi]      [Action|Adventure|Sci-Fi]   0.812545   \n",
       "4  [Action|Adventure|Sci-Fi]      [Action|Adventure|Sci-Fi]   0.618937   \n",
       "5  [Action|Adventure|Sci-Fi]      [Action|Adventure|Sci-Fi]   0.802637   \n",
       "6  [Action|Adventure|Sci-Fi]             [Action|Adventure]   0.625089   \n",
       "7         [Action|Adventure]      [Action|Adventure|Sci-Fi]   0.652773   \n",
       "8         [Action|Adventure]      [Action|Adventure|Sci-Fi]   0.668776   \n",
       "9         [Mystery|Thriller]  [Comedy|Crime|Drama|Thriller]   0.718677   \n",
       "\n",
       "       lift   support  \n",
       "0  2.980724  0.168438  \n",
       "1  2.980724  0.168438  \n",
       "2  2.709740  0.198572  \n",
       "3  2.709740  0.198572  \n",
       "4  2.676698  0.185595  \n",
       "5  2.676698  0.185595  \n",
       "6  2.671110  0.152761  \n",
       "7  2.671110  0.152761  \n",
       "8  2.230288  0.156506  \n",
       "9  1.967537  0.160860  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ant_titles = []\n",
    "cons_titles = []\n",
    "ant_genres = []\n",
    "cons_genres = []\n",
    "for ant in top_rules['antecedente']:\n",
    "    ant_title = set()\n",
    "    ant_genre = set()\n",
    "    for movie_id in ant:\n",
    "        ant_title.add(movies_dict[movie_id][0])\n",
    "        ant_genre.add(movies_dict[movie_id][1])\n",
    "    ant_titles.append(list(ant_title))\n",
    "    ant_genres.append(list(ant_genre))\n",
    "    \n",
    "for cons in top_rules['consecuente']:\n",
    "    cons_title = set()\n",
    "    cons_genre = set()\n",
    "    for movie_id in cons:\n",
    "        cons_title.add(movies_dict[movie_id][0])\n",
    "        cons_genre.add(movies_dict[movie_id][1])\n",
    "    cons_titles.append(list(cons_title))\n",
    "    cons_genres.append(list(cons_genre))\n",
    "\n",
    "\n",
    "new_columns = pd.DataFrame({'antecedente': ant_titles, 'consecuente': cons_titles,\n",
    "                           'ant_genero': ant_genres, 'cons_genero': cons_genres})\n",
    "new_top_rules = pd.concat([new_columns, top_rules[['confianza', 'lift', 'support']]], axis=1)\n",
    "pd.options.display.max_colwidth = 200\n",
    "new_top_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "A partir de lo anterior, seleccionaremos las siguientes cuatro reglas:\n",
    "\n",
    "1. **{Star Wars: Episode VI - Return of the Jedi (1983)} => {Star Wars: Episode V - The Empire Strikes Back (1980)}**\n",
    "\n",
    "    Esta regla posee alta confianza (0.72) y alto *lift* (2.98) y es la primera regla de la tabla. La alta confianza indica que en la mayoría de las veces que a un usuario le gustó *Star Wars: Episode VI* también le gustó *Star Wars: Episode V*. Notamos que la regla siguiente es la misma pero en orden invertido: esto nos indica que dentro de los usuarios que les gustó *Star Wars: Episode VI* hay **mayor** proporción de usuarios que les gustó *Star Wars: Episode V*, en comparación con esto mismo pero en orden inverso. En otras palabras, a mucha gente que le gustó la parte VI también le gustó la V, pero al revés disminuye esta proporción. \n",
    "    \n",
    "    El alto *lift* indica un alto grado de dependencia, lo que es esperable dado que se trata de películas de una misma saga.\n",
    "    \n",
    "    El soporte de esta regla es 0.16, por lo que apenas supera el soporte mínimo seleccionado. Esto indica que el *itemset* {Star Wars: Episode VI - Return of the Jedi (1983), Star Wars: Episode V - The Empire Strikes Back (1980)} aparece aproximadamente en 16% de los *itemsets* del *dataset*.\n",
    "    Notamos que, como son parte de la misma saga, se comparten los géneros (aunque esto no se da siempre).\n",
    "    \n",
    "    \n",
    "2. **{Star Wars: Episode V - The Empire Strikes Back (1980)}\t=> {Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)}**\n",
    "\n",
    "    Esta regla posee una confianza más baja que la anterior (0.62) y un alto *lift* (2.67). La confianza indica que aproximadamente un 62% de las veces que a un usuario le gustó *Star Wars: Episode V* también le gustó *Raiders of the Lost Ark*. El alto *lift* indica una alta dependencia, lo que es interesante ya que no son películas de la misma saga.\n",
    "    Notamos que estas películas comparten los géneros *Action* y *Adventure*, lo cual puede explicar el origen de esta regla de asociación.\n",
    "    \n",
    "    El soporte de esta regla es 0.15, por lo que apenas supera el soporte mínimo seleccionado. Esto indica que el *itemset* {Star Wars: Episode V - The Empire Strikes Back (1980), Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)} aparece aproximadamente en 15% de los *itemsets* del *dataset*.\n",
    "\n",
    "\n",
    "3. **{Seven (a.k.a. Se7en) (1995)} => {Pulp Fiction (1994)}**\n",
    "\n",
    "    Esta regla posee una confianza alta (0.71) y un alto *lift* (1.96). La confianza indica que aproximadamente un 71% de las veces que a un usuario le gustó *Seven* también le gustó *Pulp Fiction*. El alto *lift* indica una alta dependencia, lo que es interesante ya que no son películas de la misma saga. Este *lift* es el menor de las mejores reglas encontradas, lo que indica mayor independencia que el resto, pero de igual modo la dependencia es alta.\n",
    "    \n",
    "    Notamos que estas películas comparten el género *Thriller*, lo cual puede explicar el origen de esta regla de asociación.\n",
    "    \n",
    "    El soporte de esta regla es 0.16, por lo que apenas supera el soporte mínimo seleccionado. Esto indica que el *itemset* {Seven (a.k.a. Se7en) (1995), Pulp Fiction (1994)} aparece aproximadamente en 16% de los *itemsets* del *dataset*.\n",
    "    \n",
    "\n",
    "4. **{Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)} => {Star Wars: Episode IV - A New Hope (1977)}**\n",
    "\n",
    "    Esta regla posee una confianza alta (0.66) y un alto *lift* (2.23). La confianza indica que aproximadamente un 66% de las veces que a un usuario le gustó *Raiders of the Lost Ark* también le gustó *Star Wars: Episode IV*. El alto *lift* indica una alta dependencia, lo que es interesante ya que no son películas de la misma saga.\n",
    "    Notamos que estas películas comparten los géneros *Action* y *Adventure*, lo cual puede explicar el origen de esta regla de asociación.\n",
    "    \n",
    "    El soporte de esta regla es 0.15, por lo que apenas supera el soporte mínimo seleccionado. Esto indica que el *itemset* {Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981), Star Wars: Episode IV - A New Hope (1977)} aparece aproximadamente en 15% de los *itemsets* del *dataset*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 5\n",
    "\n",
    "Para la visualización, se utilizará la librería `altair`. El código está basado en [este ejemplo](https://altair-viz.github.io/gallery/layered_heatmap_text.html) de la documentación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-0bc4ebc76ff14a63b3598c3272b9fa8a\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-0bc4ebc76ff14a63b3598c3272b9fa8a\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-0bc4ebc76ff14a63b3598c3272b9fa8a\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": \"rect\", \"encoding\": {\"color\": {\"type\": \"quantitative\", \"field\": \"lift\", \"legend\": {\"direction\": \"horizontal\"}, \"scale\": {\"scheme\": \"darkred\"}}, \"x\": {\"type\": \"ordinal\", \"field\": \"consecuente\", \"scale\": {\"paddingInner\": 0}}, \"y\": {\"type\": \"ordinal\", \"field\": \"antecedente\", \"scale\": {\"paddingInner\": 0}}}, \"height\": 300, \"width\": 300}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\"}, \"encoding\": {\"color\": {\"condition\": {\"value\": \"black\", \"test\": \"(datum.lift > 2.5)\"}, \"value\": \"white\"}, \"text\": {\"type\": \"quantitative\", \"field\": \"lift\"}, \"x\": {\"type\": \"ordinal\", \"field\": \"consecuente\", \"scale\": {\"paddingInner\": 0}}, \"y\": {\"type\": \"ordinal\", \"field\": \"antecedente\", \"scale\": {\"paddingInner\": 0}}}, \"height\": 300, \"width\": 300}], \"data\": {\"name\": \"data-ea9cf4c9af34053221bdf730e206697d\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-ea9cf4c9af34053221bdf730e206697d\": [{\"antecedente\": [\"Star Wars: Episode V - The Empire Strikes Back (1980)\"], \"consecuente\": [\"Star Wars: Episode VI - Return of the Jedi (1983)\"], \"ant_genero\": [\"Action|Adventure|Sci-Fi\"], \"cons_genero\": [\"Action|Adventure|Sci-Fi\"], \"confianza\": 0.6892373485388453, \"lift\": 2.98, \"support\": 0.1684375544330256}, {\"antecedente\": [\"Star Wars: Episode VI - Return of the Jedi (1983)\"], \"consecuente\": [\"Star Wars: Episode V - The Empire Strikes Back (1980)\"], \"ant_genero\": [\"Action|Adventure|Sci-Fi\"], \"cons_genero\": [\"Action|Adventure|Sci-Fi\"], \"confianza\": 0.7284369114877589, \"lift\": 2.98, \"support\": 0.1684375544330256}, {\"antecedente\": [\"Star Wars: Episode IV - A New Hope (1977)\"], \"consecuente\": [\"Star Wars: Episode V - The Empire Strikes Back (1980)\"], \"ant_genero\": [\"Action|Adventure|Sci-Fi\"], \"cons_genero\": [\"Action|Adventure|Sci-Fi\"], \"confianza\": 0.6622131861748475, \"lift\": 2.71, \"support\": 0.19857167740811704}, {\"antecedente\": [\"Star Wars: Episode V - The Empire Strikes Back (1980)\"], \"consecuente\": [\"Star Wars: Episode IV - A New Hope (1977)\"], \"ant_genero\": [\"Action|Adventure|Sci-Fi\"], \"cons_genero\": [\"Action|Adventure|Sci-Fi\"], \"confianza\": 0.812544547398432, \"lift\": 2.71, \"support\": 0.19857167740811704}, {\"antecedente\": [\"Star Wars: Episode IV - A New Hope (1977)\"], \"consecuente\": [\"Star Wars: Episode VI - Return of the Jedi (1983)\"], \"ant_genero\": [\"Action|Adventure|Sci-Fi\"], \"cons_genero\": [\"Action|Adventure|Sci-Fi\"], \"confianza\": 0.6189369735695615, \"lift\": 2.68, \"support\": 0.18559484410381466}, {\"antecedente\": [\"Star Wars: Episode VI - Return of the Jedi (1983)\"], \"consecuente\": [\"Star Wars: Episode IV - A New Hope (1977)\"], \"ant_genero\": [\"Action|Adventure|Sci-Fi\"], \"cons_genero\": [\"Action|Adventure|Sci-Fi\"], \"confianza\": 0.8026365348399247, \"lift\": 2.68, \"support\": 0.18559484410381466}, {\"antecedente\": [\"Star Wars: Episode V - The Empire Strikes Back (1980)\"], \"consecuente\": [\"Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\"], \"ant_genero\": [\"Action|Adventure|Sci-Fi\"], \"cons_genero\": [\"Action|Adventure\"], \"confianza\": 0.6250890947968638, \"lift\": 2.67, \"support\": 0.15276084305870058}, {\"antecedente\": [\"Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\"], \"consecuente\": [\"Star Wars: Episode V - The Empire Strikes Back (1980)\"], \"ant_genero\": [\"Action|Adventure\"], \"cons_genero\": [\"Action|Adventure|Sci-Fi\"], \"confianza\": 0.6527726088574618, \"lift\": 2.67, \"support\": 0.15276084305870058}, {\"antecedente\": [\"Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)\"], \"consecuente\": [\"Star Wars: Episode IV - A New Hope (1977)\"], \"ant_genero\": [\"Action|Adventure\"], \"cons_genero\": [\"Action|Adventure|Sci-Fi\"], \"confianza\": 0.6687755861555639, \"lift\": 2.23, \"support\": 0.1565058352203449}, {\"antecedente\": [\"Seven (a.k.a. Se7en) (1995)\"], \"consecuente\": [\"Pulp Fiction (1994)\"], \"ant_genero\": [\"Mystery|Thriller\"], \"cons_genero\": [\"Comedy|Crime|Drama|Thriller\"], \"confianza\": 0.7186770428015564, \"lift\": 1.97, \"support\": 0.1608604772687685}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = alt.Chart(new_top_rules).properties(\n",
    "    width=300,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "\n",
    "heatmap = base.mark_rect().encode(\n",
    "    y=alt.Y('antecedente:O', scale=alt.Scale(paddingInner=0)),\n",
    "    x=alt.X('consecuente:O', scale=alt.Scale(paddingInner=0)),\n",
    "    color=alt.Color('lift:Q',\n",
    "        scale=alt.Scale(scheme='darkred'),\n",
    "        legend=alt.Legend(direction='horizontal')\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "text = base.mark_text(align='center', baseline='middle').encode(\n",
    "    y=alt.Y('antecedente:O', scale=alt.Scale(paddingInner=0)),\n",
    "    x=alt.X('consecuente:O', scale=alt.Scale(paddingInner=0)),\n",
    "    text='lift:Q',\n",
    "    color=alt.condition(\n",
    "        alt.datum.lift > 2.5,\n",
    "        alt.value('black'),\n",
    "        alt.value('white')\n",
    "    )\n",
    ")\n",
    "\n",
    "new_top_rules['lift'] = new_top_rules['lift'].apply(lambda x: round(x, 2))\n",
    "\n",
    "heatmap + text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 6\n",
    "\n",
    "Se procederá a comparar tiempos de ejecución con respecto al algoritmo de FP-Growth de la librería `mlxtend`. Por lo tanto, es necesario importar esta librería."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se transforman los datos (código tomado de la documentación de mlxtend)\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(ndarray_movies).transform(ndarray_movies)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.32 s, sys: 35.3 ms, total: 1.36 s\n",
      "Wall time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mined_mlx = fpgrowth(df, min_support=0.15, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.17 s, sys: 84.6 ms, total: 4.26 s\n",
      "Wall time: 4.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fpgrowth_test = FPGrowth()\n",
    "tree = fpgrowth_test.create_tree(ndarray_movies, 0.15)\n",
    "mined = fpgrowth_test.mine_tree(tree, 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el algoritmo implementado por mí demora más tiempo en realizarse, lo que indica que el algoritmo creado en esta tarea no fue implementado eficientemente 😔 (en comparación al de `mlxtend`).\n",
    "\n",
    "Se comparan los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     support itemsets       mined\n",
      "0   0.389131    [318]       [318]\n",
      "1   0.365267    [296]       [296]\n",
      "2   0.299861    [260]  [318, 296]\n",
      "3   0.244383   [1196]       [593]\n",
      "4   0.234018   [1198]  [318, 593]\n",
      "5   0.215206   [2959]  [296, 593]\n",
      "6   0.193869   [4993]       [356]\n",
      "7   0.188295   [2762]  [318, 356]\n",
      "8   0.172444   [5952]  [296, 356]\n",
      "9   0.157986   [7153]  [593, 356]\n",
      "10  0.150584    [541]       [260]\n",
      "11  0.268856    [110]       [527]\n",
      "\n",
      "En mi algoritmo se encontraron 59 itemsets frecuentes\n",
      "En el algoritmo de mlxtend se encontraron 59 itemsets frecuentes\n"
     ]
    }
   ],
   "source": [
    "df_mined = pd.DataFrame({'mined': mined})\n",
    "mined_mlx['mined'] = df_mined['mined']\n",
    "mined_mlx['itemsets'] = mined_mlx['itemsets'].apply(lambda x: list(x))\n",
    "print(mined_mlx.head(12))\n",
    "print(f\"\\nEn mi algoritmo se encontraron {len(mined)} itemsets frecuentes\")\n",
    "print(f\"En el algoritmo de mlxtend se encontraron {len(mined_mlx['itemsets'])} itemsets frecuentes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que los itemsets no se encuentran en el mismo orden, pues fueron minados de modo distinto. A primera vista pareciera que lo minado por `mlxtend` estuviera ordenado por soporte, pero al fijarse en los datos se tiene que esto no es así. Como las primeras dos filas tienen los mismos *itemsets*, se podría decir que los procesos de minado comenzaron igual, pero luego se separaron en funcionamiento.\n",
    "\n",
    "Para saber si efectivamente coinciden los *itemsets* frecuentes, se compararán uno a uno los datos. Como ambos resultados tienen el mismo largo, solo basta comparar con que los elementos de una lista estén todos dentro de la otra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Hay un itemset que no esté presente? False\n"
     ]
    }
   ],
   "source": [
    "list_mlx = list(map(lambda x: sorted(x), mined_mlx['itemsets'].tolist()))\n",
    "list_mined = list(map(lambda x: sorted(x), mined_mlx['mined'].tolist()))\n",
    "\n",
    "coinciden = list(map(lambda x: x in list_mlx, list_mined))\n",
    "\n",
    "print(\"¿Hay un itemset que no esté presente?\", False in coinciden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se obtuvo que el algoritmo resultó en los mismos *itemsets* frecuentes! 🥳🎉🎉 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "t01.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
